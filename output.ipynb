{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python-projects\\Kaggle\\Foursquare_Location_Matching\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "# import Kaggle API to load dataset\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import string\n",
    "import time\n",
    "import random as rnd\n",
    "import Levenshtein\n",
    "import difflib\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import lightgbm as lgb\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to force to reload dataset\n",
    "RELOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foursquare-location-matching.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# initialize Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# download dataset from Kaggle to data folder\n",
    "data_path = 'data'\n",
    "api.competition_download_files('foursquare-location-matching', data_path, force=RELOAD, quiet=False)\n",
    "# save filename: !ATTENTION! : it may not be wroking if many files are in folders\n",
    "# then just name it manually \n",
    "dataset_file_name = \"foursquare-location-matching.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train dataset (train.csv) to pandas DataFrame named df: it will be used for analysis\n",
    "df = pd.read_csv(ZipFile(os.path.join(data_path, dataset_file_name)).open('train.csv'))\n",
    "\n",
    "df_pairs = pd.read_csv(ZipFile(os.path.join(data_path, dataset_file_name)).open('pairs.csv'))\n",
    "\n",
    "# Read test dataset (test.csv), to pandas DataFrame named df_validation. It will be used only to generate final predictions, which will be submitted\n",
    "df_validation = pd.read_csv(ZipFile(os.path.join(data_path, dataset_file_name)).open('test.csv'))\n",
    "# finally, we will download example of submission (there are no correct predictions there, it is just an example)\n",
    "df_subm_example = pd.read_csv(ZipFile(os.path.join(data_path, dataset_file_name)).open('sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2022\n",
    "num_neighbors = 20\n",
    "num_split = 5\n",
    "feat_columns = ['name', 'address', 'city', \n",
    "            'state', 'zip', 'url', \n",
    "           'phone', 'categories', 'country']\n",
    "\n",
    "vec_columns = ['name', 'address', 'city', 'state', 'zip', 'country', 'categories']\n",
    "\n",
    "def seed_everything(seed):\n",
    "    rnd.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (1138812, 13)\n",
      "Shape of df_pairs: (578907, 25)\n",
      "Shape of df_validation: (5, 12)\n",
      "Shape of df_subm_example: (5, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check, that all dataframes are loaded and have correct shapes\n",
    "print(f'Shape of df: {str(df.shape)}')\n",
    "print(f'Shape of df_pairs: {str(df_pairs.shape)}')\n",
    "print(f'Shape of df_validation: {str(df_validation.shape)}')\n",
    "print(f'Shape of df_subm_example: {str(df_subm_example.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = list(df_pairs['id_1'])\n",
    "all_ids.extend(list(df_pairs['id_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157814"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = list(dict.fromkeys(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008661"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_pairs[df_pairs['match']][['id_1', 'id_2']]\n",
    "#df_out_2 = df_pairs[df_pairs['match']][['id_1', 'id_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398786, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm = df_out.groupby('id_1')['id_2'].apply(list).reset_index(name='matches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lst): \n",
    "    return ' '.join(lst)\n",
    "\n",
    "df_subm['match_id'] = df_subm['matches'].apply(lambda x: convert(x))\n",
    "df_subm.drop('matches', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>match_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E_000001272c6c5d</td>\n",
       "      <td>E_da7fa3963561f8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E_000023d8f4be44</td>\n",
       "      <td>E_12453effe251db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E_00007dcd2bb53f</td>\n",
       "      <td>E_f131dcb7f07be9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E_0000c566a81ea1</td>\n",
       "      <td>E_8d58f3151bae83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E_0000d9e584ed9f</td>\n",
       "      <td>E_caad79f6ed7c44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314980</th>\n",
       "      <td>E_ffff2b8abf31ab</td>\n",
       "      <td>E_3798ed1302222c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314981</th>\n",
       "      <td>E_ffff7b1a22e81b</td>\n",
       "      <td>E_fb8ac113943b2f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314982</th>\n",
       "      <td>E_ffff80f94b2fee</td>\n",
       "      <td>E_75feaa1e0321cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314983</th>\n",
       "      <td>E_ffff989ae206f8</td>\n",
       "      <td>E_a5bc397a4eaeff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314984</th>\n",
       "      <td>E_ffffca745329ed</td>\n",
       "      <td>E_04988888cfff60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314985 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id_1          match_id\n",
       "0       E_000001272c6c5d  E_da7fa3963561f8\n",
       "1       E_000023d8f4be44  E_12453effe251db\n",
       "2       E_00007dcd2bb53f  E_f131dcb7f07be9\n",
       "3       E_0000c566a81ea1  E_8d58f3151bae83\n",
       "4       E_0000d9e584ed9f  E_caad79f6ed7c44\n",
       "...                  ...               ...\n",
       "314980  E_ffff2b8abf31ab  E_3798ed1302222c\n",
       "314981  E_ffff7b1a22e81b  E_fb8ac113943b2f\n",
       "314982  E_ffff80f94b2fee  E_75feaa1e0321cc\n",
       "314983  E_ffff989ae206f8  E_a5bc397a4eaeff\n",
       "314984  E_ffffca745329ed  E_04988888cfff60\n",
       "\n",
       "[314985 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm.to_csv('.\\\\data\\\\test_my_submission.csv', index=False, doublequote=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3abc7ea86c1ba1384b4878b98af82991463d4da0cba7b7e72c3eaf31f3854092"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
