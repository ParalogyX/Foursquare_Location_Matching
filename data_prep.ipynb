{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python-projects\\Kaggle\\Foursquare_Location_Matching\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "# import Kaggle API to load dataset\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import string\n",
    "import time\n",
    "import random as rnd\n",
    "import Levenshtein\n",
    "import difflib\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import lightgbm as lgb\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to force to reload dataset\n",
    "RELOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foursquare-location-matching.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# initialize Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# download dataset from Kaggle to data folder\n",
    "data_path = 'data'\n",
    "api.competition_download_files('foursquare-location-matching', data_path, force=RELOAD, quiet=False)\n",
    "# save filename: !ATTENTION! : it may not be wroking if many files are in folders\n",
    "# then just name it manually \n",
    "dataset_file_name = os.listdir(data_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train dataset (train.csv) to pandas DataFrame named df: it will be used for analysis\n",
    "df = pd.read_csv(ZipFile(os.path.join(data_path, dataset_file_name)).open('train.csv'))\n",
    "\n",
    "df_pairs = pd.read_csv(ZipFile(os.path.join(data_path, dataset_file_name)).open('pairs.csv'))\n",
    "\n",
    "# Read test dataset (test.csv), to pandas DataFrame named df_validation. It will be used only to generate final predictions, which will be submitted\n",
    "df_validation = pd.read_csv(ZipFile(os.path.join(data_path, dataset_file_name)).open('test.csv'))\n",
    "# finally, we will download example of submission (there are no correct predictions there, it is just an example)\n",
    "df_subm_example = pd.read_csv(ZipFile(os.path.join(data_path, dataset_file_name)).open('sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2022\n",
    "num_neighbors = 20\n",
    "num_split = 5\n",
    "feat_columns = ['name', 'address', 'city', \n",
    "            'state', 'zip', 'url', \n",
    "           'phone', 'categories', 'country']\n",
    "\n",
    "vec_columns = ['name', 'address', 'city', 'state', 'zip', 'country', 'categories']\n",
    "\n",
    "def seed_everything(seed):\n",
    "    rnd.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (1138812, 13)\n",
      "Shape of df_pairs: (578907, 25)\n",
      "Shape of df_validation: (5, 12)\n",
      "Shape of df_subm_example: (5, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check, that all dataframes are loaded and have correct shapes\n",
    "print(f'Shape of df: {str(df.shape)}')\n",
    "print(f'Shape of df_pairs: {str(df_pairs.shape)}')\n",
    "print(f'Shape of df_validation: {str(df_validation.shape)}')\n",
    "print(f'Shape of df_subm_example: {str(df_subm_example.shape)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ideas and helper functions are from https://www.kaggle.com/code/guoyonfan/training-data-for-binary-lgb-baseline-0-834"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is quiet big, so we can split it to train-test-validation datasets in 2/5-2/5-1/5. df_validation, provided by Kaggle will be ignored in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_train: (455524, 13)\n",
      "Shape of df_test: (455525, 13)\n",
      "Shape of df_val: (227763, 13)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.6)\n",
    "df_test, df_val  = train_test_split(df_test, test_size=(1/3))\n",
    "print(f'Shape of df_train: {str(df_train.shape)}')\n",
    "print(f'Shape of df_test: {str(df_test.shape)}')\n",
    "print(f'Shape of df_val: {str(df_val.shape)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text):\n",
    "    # zip field, sometimes is read as float\n",
    "    if not isinstance(text,str):\n",
    "        text = str(int(text))\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    text = text.lower()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop=['phone', 'url']):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(self.columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanString(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, coulums_to_clean=['name', 'address', 'city', 'state', 'zip', 'country', 'categories']):\n",
    "        self.columns_to_clean = coulums_to_clean\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        for col in self.columns_to_clean:\n",
    "            X[f'{col}_clean']=X[col].map(clean_string, na_action='ignore')\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VecString(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, coulums_to_vec=['name', 'address', 'city', 'state', 'zip', 'country', 'categories']):\n",
    "        self.coulums_to_vec = coulums_to_vec\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        for col in self.coulums_to_vec:\n",
    "            tfidf = TfidfVectorizer(max_features=40)\n",
    "            tv_fit = tfidf.fit_transform(X[f'{col}_clean'].fillna('nan'))\n",
    "            X[f'{col}_vec'] = list(tv_fit.toarray())\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train (and also test set, which will be used for final evaluation) set is too large to combine all entries with each other and check if it refers to the same POI or not.\n",
    "Therefore perform unsupervised KNN by geo location, address and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_knn(df, Neighbors = 5):   \n",
    "    neighbors = min(len(df), Neighbors)\n",
    "    train_df = []\n",
    "    knn = NearestNeighbors(n_neighbors = neighbors)\n",
    "    knn.fit(df[['latitude','longitude']])\n",
    "    dists, nears = knn.kneighbors(df[['latitude','longitude']])\n",
    "    \n",
    "    for k in range(neighbors):            \n",
    "        cur_df = df[['id']].copy()\n",
    "        cur_df['match_id'] = df['id'].values[nears[:, k]]\n",
    "        cur_df['kdist'] = dists[:, k]\n",
    "        cur_df['kneighbors'] = k\n",
    "        train_df.append(cur_df)\n",
    "    \n",
    "    train_df = pd.concat(train_df)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_knn_text(df, Neighbors = 5):   \n",
    "    train_df = []\n",
    "    knn = NearestNeighbors(n_neighbors = Neighbors)\n",
    "    knn.fit(df['name_vec'])\n",
    "    dists, nears = knn.kneighbors(df['name_vec'])\n",
    "    \n",
    "    for k in range(Neighbors):            \n",
    "        cur_df = df[['id']].copy()\n",
    "        cur_df['match_id'] = df['id'].values[nears[:, k]]\n",
    "        cur_df['kdist'] = dists[:, k]\n",
    "        cur_df['kneighbors'] = k\n",
    "        train_df.append(cur_df)\n",
    "    \n",
    "    train_df = pd.concat(train_df)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Knn_geo(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = recall_knn(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Knn_text(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = recall_knn_text(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_records(df):  \n",
    "    \n",
    "    df_knn = recall_knn(df)\n",
    "      \n",
    "    merged_df = df_knn.merge(df, how='inner', left_on='id', right_on='id')\n",
    "    df_pairs_custom = merged_df.merge(df, how='inner', left_on='match_id', right_on='id')\n",
    "    df_pairs_custom.drop(['match_id'], axis=1, inplace=True)\n",
    "    train = ('point_of_interest' in df.columns)\n",
    "    if train:\n",
    "        df_pairs_custom['match'] = df_pairs_custom['point_of_interest_x'] == df_pairs_custom['point_of_interest_y']\n",
    "        df_pairs_custom.drop(['point_of_interest_x', 'point_of_interest_y'], axis=1, inplace=True)\n",
    "\n",
    "    # df_pairs_custom.drop(['name_clean_x', 'address_clean_x', 'city_clean_x', 'state_clean_x', 'zip_clean_x', 'country_clean_x', 'categories_clean_x',\n",
    "    #                         'name_clean_y', 'address_clean_y', 'city_clean_y', 'state_clean_y', 'zip_clean_y', 'country_clean_y', 'categories_clean_y'], axis=1, inplace=True)\n",
    "\n",
    "    # columns = ['id_1', 'geo_k_dist', 'geo_k_neigh', 'latitude_1', 'longitude_1', 'name_1', 'address_1', 'city_1', 'state_1', 'zip_1', 'country_1', 'categories_1',\n",
    "    #                                 'name_vec_1', 'address_vec_1', 'city_vec_1', 'state_vec_1', 'zip_vec_1', 'country_vec_1', 'categories_vec_1',\n",
    "    #                                 'id_2', 'latitude_2', 'longitude_2', 'name_2', 'address_2', 'city_2', 'state_2', 'zip_2', 'country_2', 'categories_2',\n",
    "    #                                 'name_vec_2', 'address_vec_2', 'city_vec_2', 'state_vec_2', 'zip_vec_2', 'country_vec_2', 'categories_vec_2']\n",
    "\n",
    "    columns = ['id_1', 'geo_k_dist', 'geo_k_neigh', 'latitude_1', 'longitude_1', 'name_1', 'address_1', 'city_1', 'state_1', 'zip_1', 'country_1', 'categories_1',\n",
    "                                    'id_2', 'latitude_2', 'longitude_2', 'name_2', 'address_2', 'city_2', 'state_2', 'zip_2', 'country_2', 'categories_2']\n",
    "\n",
    "    if train: columns.append('match')\n",
    "    df_pairs_custom.columns=columns\n",
    "\n",
    "    return df_pairs_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinePairs(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = combine_records(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def LCS(str S, str T):\n",
    "    cdef int i, j\n",
    "    cdef list dp = [[0] * (len(T) + 1) for _ in range(len(S) + 1)]\n",
    "    for i in range(len(S)):\n",
    "        for j in range(len(T)):\n",
    "            dp[i + 1][j + 1] = max(dp[i][j] + (S[i] == T[j]), dp[i + 1][j], dp[i][j + 1], dp[i + 1][j + 1])\n",
    "    return dp[len(S)][len(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim (vec1, vec2):\n",
    "    vec1 = vec1.reshape(1, -1)\n",
    "    vec2 = vec2.reshape(1, -1)\n",
    "\n",
    "    return cosine_similarity(vec1, vec2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df, str_cols=['name', 'address', 'city', 'state', 'zip', 'country', 'categories']):\n",
    "    df_new = df.copy()\n",
    "    for col in str_cols:\n",
    "        # Add string distances to df\n",
    "        df_new[f'{col}_lev'] = df_new.apply(lambda x: Levenshtein.distance(str(x[f'{col}_1']), str(x[f'{col}_2'])), axis=1)\n",
    "        df_new[f'{col}_jaro'] = df_new.apply(lambda x: Levenshtein.jaro_winkler(str(x[f'{col}_1']), str(x[f'{col}_2'])), axis=1)\n",
    "        df_new[f'{col}_seq_match'] = df_new.apply(lambda x: difflib.SequenceMatcher(None, str(x[f'{col}_1']), str(x[f'{col}_2'])).ratio(), axis=1)\n",
    "        df_new[f'{col}_lcs'] = df_new.apply(lambda x: LCS(str(x[f'{col}_1']), str(x[f'{col}_2'])), axis=1)\n",
    "\n",
    "        # Vector distances\n",
    "        #df_new[f'{col}_cos_sim'] = df_new.apply(lambda x: cosine_sim(x[f'{col}_vec_1'], x[f'{col}_vec_2']), axis=1)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    # df_new.drop(['latitude_1', 'longitude_1', 'name_1', 'address_1', 'city_1', 'state_1', 'zip_1', 'country_1', 'categories_1', \n",
    "    #             'name_vec_1', 'address_vec_1', 'city_vec_1', 'state_vec_1', 'zip_vec_1', 'country_vec_1', 'categories_vec_1', \n",
    "    #             'latitude_2', 'longitude_2', 'name_2', 'address_2', 'city_2', 'state_2', 'zip_2', 'country_2', 'categories_2', \n",
    "    #             'name_vec_2', 'address_vec_2', 'city_vec_2', 'state_vec_2', 'zip_vec_2', 'country_vec_2', 'categories_vec_2'], axis=1, inplace=True)\n",
    "\n",
    "    df_new.drop(['latitude_1', 'longitude_1', 'name_1', 'address_1', 'city_1', 'state_1', 'zip_1', 'country_1', 'categories_1',  \n",
    "                'latitude_2', 'longitude_2', 'name_2', 'address_2', 'city_2', 'state_2', 'zip_2', 'country_2', 'categories_2'], axis=1, inplace=True)                \n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = add_features(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('dropper1', ColDropper()),\n",
    "    ('cleaner', CleanString()),\n",
    "    #('vector', VecString()),\n",
    "    ('dropper2', ColDropper(columns_to_drop=['name', 'address', 'city', 'state', 'zip', 'country', 'categories'])),\n",
    "    ('combinator', CombinePairs()),\n",
    "    ('add_features', AddFeatures())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>geo_k_dist</th>\n",
       "      <th>geo_k_neigh</th>\n",
       "      <th>id_2</th>\n",
       "      <th>match</th>\n",
       "      <th>name_lev</th>\n",
       "      <th>name_jaro</th>\n",
       "      <th>name_seq_match</th>\n",
       "      <th>name_lcs</th>\n",
       "      <th>address_lev</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_seq_match</th>\n",
       "      <th>zip_lcs</th>\n",
       "      <th>country_lev</th>\n",
       "      <th>country_jaro</th>\n",
       "      <th>country_seq_match</th>\n",
       "      <th>country_lcs</th>\n",
       "      <th>categories_lev</th>\n",
       "      <th>categories_jaro</th>\n",
       "      <th>categories_seq_match</th>\n",
       "      <th>categories_lcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E_ed3ebf16f35c42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>E_ed3ebf16f35c42</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E_8c6f6bb7818f9f</td>\n",
       "      <td>1.036040</td>\n",
       "      <td>3</td>\n",
       "      <td>E_ed3ebf16f35c42</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>0.603980</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E_010b0c730f3f37</td>\n",
       "      <td>1.377660</td>\n",
       "      <td>4</td>\n",
       "      <td>E_ed3ebf16f35c42</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>0.504047</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E_de36268a1b5cfb</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>2</td>\n",
       "      <td>E_ed3ebf16f35c42</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>0.611736</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E_d1694abd2949b2</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>3</td>\n",
       "      <td>E_ed3ebf16f35c42</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>0.407469</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.423903</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id_1  geo_k_dist  geo_k_neigh              id_2  match  \\\n",
       "0  E_ed3ebf16f35c42    0.000000            0  E_ed3ebf16f35c42   True   \n",
       "1  E_8c6f6bb7818f9f    1.036040            3  E_ed3ebf16f35c42  False   \n",
       "2  E_010b0c730f3f37    1.377660            4  E_ed3ebf16f35c42  False   \n",
       "3  E_de36268a1b5cfb    0.019107            2  E_ed3ebf16f35c42  False   \n",
       "4  E_d1694abd2949b2    0.005195            3  E_ed3ebf16f35c42  False   \n",
       "\n",
       "   name_lev  name_jaro  name_seq_match  name_lcs  address_lev  ...  \\\n",
       "0         0   1.000000        1.000000        23            0  ...   \n",
       "1        18   0.603980        0.378378         8           12  ...   \n",
       "2        18   0.504047        0.176471         5           14  ...   \n",
       "3        25   0.611736        0.339623         9            3  ...   \n",
       "4        19   0.407469        0.388889         7           14  ...   \n",
       "\n",
       "   zip_seq_match  zip_lcs  country_lev  country_jaro  country_seq_match  \\\n",
       "0            1.0        4            0           1.0                1.0   \n",
       "1            0.0        0            0           1.0                1.0   \n",
       "2            0.0        0            0           1.0                1.0   \n",
       "3            0.5        2            0           1.0                1.0   \n",
       "4            0.0        0            0           1.0                1.0   \n",
       "\n",
       "   country_lcs  categories_lev  categories_jaro  categories_seq_match  \\\n",
       "0            2               0         1.000000              1.000000   \n",
       "1            2               7         0.000000              0.000000   \n",
       "2            2               8         0.417989              0.125000   \n",
       "3            2               9         0.448413              0.210526   \n",
       "4            2              14         0.423903              0.250000   \n",
       "\n",
       "   categories_lcs  \n",
       "0               7  \n",
       "1               0  \n",
       "2               1  \n",
       "3               3  \n",
       "4               4  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_prep = pipe.fit_transform(df_train)\n",
    "df_train_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>geo_k_dist</th>\n",
       "      <th>geo_k_neigh</th>\n",
       "      <th>id_2</th>\n",
       "      <th>match</th>\n",
       "      <th>name_lev</th>\n",
       "      <th>name_jaro</th>\n",
       "      <th>name_seq_match</th>\n",
       "      <th>name_lcs</th>\n",
       "      <th>address_lev</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_seq_match</th>\n",
       "      <th>zip_lcs</th>\n",
       "      <th>country_lev</th>\n",
       "      <th>country_jaro</th>\n",
       "      <th>country_seq_match</th>\n",
       "      <th>country_lcs</th>\n",
       "      <th>categories_lev</th>\n",
       "      <th>categories_jaro</th>\n",
       "      <th>categories_seq_match</th>\n",
       "      <th>categories_lcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E_e1c1e1ccc57cd6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>E_e1c1e1ccc57cd6</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E_c74bdc3b3c735f</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>2</td>\n",
       "      <td>E_e1c1e1ccc57cd6</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.519444</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E_e1c1e1ccc57cd6</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>1</td>\n",
       "      <td>E_2ff76cd6dd345a</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.736988</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E_5397628843ad6a</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1</td>\n",
       "      <td>E_2ff76cd6dd345a</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>0.547222</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.572872</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E_c74bdc3b3c735f</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>3</td>\n",
       "      <td>E_2ff76cd6dd345a</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.465657</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id_1  geo_k_dist  geo_k_neigh              id_2  match  \\\n",
       "0  E_e1c1e1ccc57cd6    0.000000            0  E_e1c1e1ccc57cd6   True   \n",
       "1  E_c74bdc3b3c735f    0.001259            2  E_e1c1e1ccc57cd6  False   \n",
       "2  E_e1c1e1ccc57cd6    0.001156            1  E_2ff76cd6dd345a  False   \n",
       "3  E_5397628843ad6a    0.000235            1  E_2ff76cd6dd345a  False   \n",
       "4  E_c74bdc3b3c735f    0.001464            3  E_2ff76cd6dd345a  False   \n",
       "\n",
       "   name_lev  name_jaro  name_seq_match  name_lcs  address_lev  ...  \\\n",
       "0         0   1.000000        1.000000         9            0  ...   \n",
       "1         7   0.518519        0.266667         2            3  ...   \n",
       "2         9   0.433333        0.210526         2            3  ...   \n",
       "3        13   0.547222        0.230769         3            0  ...   \n",
       "4         9   0.422222        0.125000         1            0  ...   \n",
       "\n",
       "   zip_seq_match  zip_lcs  country_lev  country_jaro  country_seq_match  \\\n",
       "0            1.0        3            0           1.0                1.0   \n",
       "1            1.0        3            0           1.0                1.0   \n",
       "2            1.0        3            0           1.0                1.0   \n",
       "3            1.0        3            0           1.0                1.0   \n",
       "4            1.0        3            0           1.0                1.0   \n",
       "\n",
       "   country_lcs  categories_lev  categories_jaro  categories_seq_match  \\\n",
       "0            2               0         1.000000              1.000000   \n",
       "1            2              16         0.519444              0.228571   \n",
       "2            2               6         0.736988              0.761905   \n",
       "3            2              16         0.572872              0.333333   \n",
       "4            2              18         0.465657              0.216216   \n",
       "\n",
       "   categories_lcs  \n",
       "0              20  \n",
       "1               5  \n",
       "2              16  \n",
       "3               7  \n",
       "4               4  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_prep = pipe.fit_transform(df_test)\n",
    "df_test_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>geo_k_dist</th>\n",
       "      <th>geo_k_neigh</th>\n",
       "      <th>id_2</th>\n",
       "      <th>match</th>\n",
       "      <th>name_lev</th>\n",
       "      <th>name_jaro</th>\n",
       "      <th>name_seq_match</th>\n",
       "      <th>name_lcs</th>\n",
       "      <th>address_lev</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_seq_match</th>\n",
       "      <th>zip_lcs</th>\n",
       "      <th>country_lev</th>\n",
       "      <th>country_jaro</th>\n",
       "      <th>country_seq_match</th>\n",
       "      <th>country_lcs</th>\n",
       "      <th>categories_lev</th>\n",
       "      <th>categories_jaro</th>\n",
       "      <th>categories_seq_match</th>\n",
       "      <th>categories_lcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E_3a797712ed240d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>E_3a797712ed240d</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E_6467f7e0ae52de</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>4</td>\n",
       "      <td>E_3a797712ed240d</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E_8a83270d4fe433</td>\n",
       "      <td>0.012368</td>\n",
       "      <td>3</td>\n",
       "      <td>E_3a797712ed240d</td>\n",
       "      <td>False</td>\n",
       "      <td>37</td>\n",
       "      <td>0.348148</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.523148</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E_f2351063814e92</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>3</td>\n",
       "      <td>E_3a797712ed240d</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>0.541532</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.523403</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E_7c18753a42b8a1</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>3</td>\n",
       "      <td>E_3a797712ed240d</td>\n",
       "      <td>False</td>\n",
       "      <td>34</td>\n",
       "      <td>0.465476</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.575926</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id_1  geo_k_dist  geo_k_neigh              id_2  match  \\\n",
       "0  E_3a797712ed240d    0.000000            0  E_3a797712ed240d   True   \n",
       "1  E_6467f7e0ae52de    0.015526            4  E_3a797712ed240d  False   \n",
       "2  E_8a83270d4fe433    0.012368            3  E_3a797712ed240d  False   \n",
       "3  E_f2351063814e92    0.013139            3  E_3a797712ed240d  False   \n",
       "4  E_7c18753a42b8a1    0.004868            3  E_3a797712ed240d  False   \n",
       "\n",
       "   name_lev  name_jaro  name_seq_match  name_lcs  address_lev  ...  \\\n",
       "0         0   1.000000        1.000000        40            0  ...   \n",
       "1        33   0.400000        0.214286         8           18  ...   \n",
       "2        37   0.348148        0.081633         3           13  ...   \n",
       "3        33   0.541532        0.203390         9           13  ...   \n",
       "4        34   0.465476        0.185185         7            9  ...   \n",
       "\n",
       "   zip_seq_match  zip_lcs  country_lev  country_jaro  country_seq_match  \\\n",
       "0            1.0        5            0           1.0                1.0   \n",
       "1            1.0        5            0           1.0                1.0   \n",
       "2            1.0        5            0           1.0                1.0   \n",
       "3            1.0        5            0           1.0                1.0   \n",
       "4            1.0        5            0           1.0                1.0   \n",
       "\n",
       "   country_lcs  categories_lev  categories_jaro  categories_seq_match  \\\n",
       "0            2               0         1.000000              1.000000   \n",
       "1            2              16         0.435185              0.272727   \n",
       "2            2              12         0.523148              0.470588   \n",
       "3            2              32         0.523403              0.266667   \n",
       "4            2              15         0.575926              0.303030   \n",
       "\n",
       "   categories_lcs  \n",
       "0              18  \n",
       "1               3  \n",
       "2               8  \n",
       "3              11  \n",
       "4               5  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_prep = pipe.fit_transform(df_val)\n",
    "df_val_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_1</th>\n",
       "      <th>geo_k_dist</th>\n",
       "      <th>geo_k_neigh</th>\n",
       "      <th>id_2</th>\n",
       "      <th>name_lev</th>\n",
       "      <th>name_jaro</th>\n",
       "      <th>name_seq_match</th>\n",
       "      <th>name_lcs</th>\n",
       "      <th>address_lev</th>\n",
       "      <th>address_jaro</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_seq_match</th>\n",
       "      <th>zip_lcs</th>\n",
       "      <th>country_lev</th>\n",
       "      <th>country_jaro</th>\n",
       "      <th>country_seq_match</th>\n",
       "      <th>country_lcs</th>\n",
       "      <th>categories_lev</th>\n",
       "      <th>categories_jaro</th>\n",
       "      <th>categories_seq_match</th>\n",
       "      <th>categories_lcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E_00001118ad0191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>E_00001118ad0191</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E_000020eb6fed40</td>\n",
       "      <td>184.531619</td>\n",
       "      <td>2</td>\n",
       "      <td>E_00001118ad0191</td>\n",
       "      <td>18</td>\n",
       "      <td>0.546552</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E_00002f98667edf</td>\n",
       "      <td>74.052538</td>\n",
       "      <td>1</td>\n",
       "      <td>E_00001118ad0191</td>\n",
       "      <td>21</td>\n",
       "      <td>0.431159</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E_001b6bad66eb98</td>\n",
       "      <td>9.086563</td>\n",
       "      <td>2</td>\n",
       "      <td>E_00001118ad0191</td>\n",
       "      <td>29</td>\n",
       "      <td>0.587754</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E_0283d9f61e569d</td>\n",
       "      <td>9.090103</td>\n",
       "      <td>2</td>\n",
       "      <td>E_00001118ad0191</td>\n",
       "      <td>21</td>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id_1  geo_k_dist  geo_k_neigh              id_2  name_lev  \\\n",
       "0  E_00001118ad0191    0.000000            0  E_00001118ad0191         0   \n",
       "1  E_000020eb6fed40  184.531619            2  E_00001118ad0191        18   \n",
       "2  E_00002f98667edf   74.052538            1  E_00001118ad0191        21   \n",
       "3  E_001b6bad66eb98    9.086563            2  E_00001118ad0191        29   \n",
       "4  E_0283d9f61e569d    9.090103            2  E_00001118ad0191        21   \n",
       "\n",
       "   name_jaro  name_seq_match  name_lcs  address_lev  address_jaro  ...  \\\n",
       "0   1.000000        1.000000        23            0      1.000000  ...   \n",
       "1   0.546552        0.352941         6           12      0.470085  ...   \n",
       "2   0.431159        0.148148         2           16      0.000000  ...   \n",
       "3   0.587754        0.354839        12            0      1.000000  ...   \n",
       "4   0.587819        0.382979        10           25      0.591270  ...   \n",
       "\n",
       "   zip_seq_match  zip_lcs  country_lev  country_jaro  country_seq_match  \\\n",
       "0            1.0        3            0           1.0                1.0   \n",
       "1            0.0        0            2           0.0                0.0   \n",
       "2            1.0        3            2           0.0                0.0   \n",
       "3            1.0        3            2           0.0                0.0   \n",
       "4            0.0        0            2           0.0                0.0   \n",
       "\n",
       "   country_lcs  categories_lev  categories_jaro  categories_seq_match  \\\n",
       "0            2               0         1.000000              1.000000   \n",
       "1            0               3         0.633333              0.444444   \n",
       "2            0               3         0.633333              0.444444   \n",
       "3            0               6         0.550000              0.153846   \n",
       "4            0              12         0.344444              0.100000   \n",
       "\n",
       "   categories_lcs  \n",
       "0               5  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               3  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To test how it works with final validation without POI\n",
    "df_validation_prep = pipe.fit_transform(df_validation)\n",
    "df_validation_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('.\\\\data\\\\custom_prep\\\\'):\n",
    "    os.makedirs('.\\\\data\\\\custom_prep\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep.to_csv('.\\\\data\\\\custom_prep\\\\train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prep.to_csv('.\\\\data\\\\custom_prep\\\\test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_prep.to_csv('.\\\\data\\\\custom_prep\\\\val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_prep.to_csv('.\\\\data\\\\custom_prep\\\\final_validation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3abc7ea86c1ba1384b4878b98af82991463d4da0cba7b7e72c3eaf31f3854092"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
